{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, xyz2lab\n",
    "from skimage.io import imsave\n",
    "from PIL import Image\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
    "    with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        # note the encoding type is 'latin1'\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleImage(inputMatrix):\n",
    "    #vecShape = np.shape(inputMatrix)\n",
    "    #print(vecShape)\n",
    "    #vecShape(1) = 400\n",
    "    #vecShape(2) = 400\n",
    "    retMatrix = np.zeros([500, 400, 400, 3])\n",
    "    for num in range(np.shape(retMatrix)[0]):\n",
    "        img = Image.fromarray(inputMatrix[num,:,:,:], 'RGB')\n",
    "\n",
    "        #resizedImage = img.resize([400,400], resample=0, box=None)\n",
    "        #resizedImage.size\n",
    "        retMatrix[num,:,:,:] = np.array(img.resize([400,400], resample=0, box=None))\n",
    "        #np.shape(pix)\n",
    "    return retMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images\n",
    "pictures, labels = load_cfar10_batch('C:/Users/adith/Documents/MLAB CAR/CIFAR_data/cifar-10-batches-py', 1)\n",
    "resizePictures = scaleImage(pictures)\n",
    "image = resizePictures\n",
    "# img = load_img('human.png').resize([400,400], resample=0, box=None)\n",
    "# image = img_to_array(img)\n",
    "# image = np.array(image, dtype=float)\n",
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rgb2lab(1.0/255*image)[:,:,:,0]\n",
    "Y = rgb2lab(1.0/255*image)[:,:,:,1:]\n",
    "Y /= 128\n",
    "X = X.reshape(500, 400, 400, 1)\n",
    "Y = Y.reshape(500, 400, 400, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the neural network\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(None, None, 1)))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish model\n",
    "model.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "500/500 [==============================] - 173s 346ms/step - loss: 0.0223\n",
      "Epoch 2/40\n",
      "500/500 [==============================] - 198s 396ms/step - loss: 0.0114\n",
      "Epoch 3/40\n",
      "500/500 [==============================] - 215s 429ms/step - loss: 0.0113\n",
      "Epoch 4/40\n",
      "500/500 [==============================] - 163s 327ms/step - loss: 0.0113\n",
      "Epoch 5/40\n",
      "500/500 [==============================] - 181s 361ms/step - loss: 0.0113\n",
      "Epoch 6/40\n",
      "500/500 [==============================] - 218s 436ms/step - loss: 0.0113\n",
      "Epoch 7/40\n",
      "500/500 [==============================] - 228s 457ms/step - loss: 0.0112\n",
      "Epoch 8/40\n",
      "500/500 [==============================] - 219s 438ms/step - loss: 0.0113\n",
      "Epoch 9/40\n",
      "500/500 [==============================] - 210s 421ms/step - loss: 0.0112\n",
      "Epoch 10/40\n",
      "500/500 [==============================] - 193s 387ms/step - loss: 0.0116\n",
      "Epoch 11/40\n",
      "500/500 [==============================] - 175s 350ms/step - loss: 0.0113\n",
      "Epoch 12/40\n",
      "500/500 [==============================] - 174s 348ms/step - loss: 0.0112\n",
      "Epoch 13/40\n",
      "500/500 [==============================] - 199s 397ms/step - loss: 0.0112\n",
      "Epoch 14/40\n",
      "500/500 [==============================] - 183s 367ms/step - loss: 0.0113\n",
      "Epoch 15/40\n",
      "500/500 [==============================] - 180s 359ms/step - loss: 0.0112\n",
      "Epoch 16/40\n",
      "500/500 [==============================] - 182s 365ms/step - loss: 0.0113\n",
      "Epoch 17/40\n",
      "500/500 [==============================] - 222s 444ms/step - loss: 0.0113\n",
      "Epoch 18/40\n",
      "500/500 [==============================] - 5236s 10s/step - loss: 0.0112\n",
      "Epoch 19/40\n",
      "500/500 [==============================] - 233s 465ms/step - loss: 0.0111\n",
      "Epoch 20/40\n",
      "500/500 [==============================] - 283s 565ms/step - loss: 0.0112\n",
      "Epoch 21/40\n",
      "500/500 [==============================] - 197s 394ms/step - loss: 0.0113\n",
      "Epoch 22/40\n",
      "500/500 [==============================] - 223s 446ms/step - loss: 0.0115\n",
      "Epoch 23/40\n",
      "500/500 [==============================] - 168s 336ms/step - loss: 0.0113\n",
      "Epoch 24/40\n",
      "500/500 [==============================] - 262s 523ms/step - loss: 0.0112\n",
      "Epoch 25/40\n",
      "500/500 [==============================] - 206s 412ms/step - loss: 0.0112\n",
      "Epoch 26/40\n",
      "500/500 [==============================] - 146s 292ms/step - loss: 0.0112\n",
      "Epoch 27/40\n",
      "500/500 [==============================] - 159s 318ms/step - loss: 0.0114\n",
      "Epoch 28/40\n",
      "500/500 [==============================] - 191s 382ms/step - loss: 0.0112\n",
      "Epoch 29/40\n",
      "500/500 [==============================] - 181s 362ms/step - loss: 0.0111\n",
      "Epoch 30/40\n",
      "500/500 [==============================] - 160s 321ms/step - loss: 0.0112\n",
      "Epoch 31/40\n",
      "500/500 [==============================] - 180s 359ms/step - loss: 0.0111\n",
      "Epoch 32/40\n",
      "500/500 [==============================] - 214s 429ms/step - loss: 0.0110\n",
      "Epoch 33/40\n",
      "500/500 [==============================] - 174s 349ms/step - loss: 0.0112\n",
      "Epoch 34/40\n",
      "500/500 [==============================] - 176s 351ms/step - loss: 0.0110\n",
      "Epoch 35/40\n",
      "500/500 [==============================] - 193s 386ms/step - loss: 0.0111\n",
      "Epoch 36/40\n",
      "500/500 [==============================] - 204s 409ms/step - loss: 0.0110\n",
      "Epoch 37/40\n",
      "500/500 [==============================] - 193s 386ms/step - loss: 0.0112\n",
      "Epoch 38/40\n",
      "500/500 [==============================] - 242s 483ms/step - loss: 0.0110\n",
      "Epoch 39/40\n",
      "500/500 [==============================] - 224s 448ms/step - loss: 0.0115\n",
      "Epoch 40/40\n",
      "500/500 [==============================] - 234s 468ms/step - loss: 0.0111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dad63187b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X, y=Y, batch_size=5, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = load_img('human.png').resize([400,400], resample=0, box=None)\n",
    "imageToTest = img_to_array(img)\n",
    "imageToTest = np.array(imageToTest, dtype=float)\n",
    "XTest = rgb2lab(1.0/255*imageToTest)[:,:,0]\n",
    "YTest = rgb2lab(1.0/255*imageToTest)[:,:,1:]\n",
    "YTest /= 128\n",
    "np.shape(YTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTest = XTest.reshape(1, 400, 400, 1)\n",
    "YTest = YTest.reshape(1, 400, 400, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 115ms/step\n",
      "0.017200805246829987\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(XTest, YTest, batch_size=1))\n",
    "output = model.predict(XTest)\n",
    "output *= 128\n",
    "# Output colorizations\n",
    "cur = np.zeros((400, 400, 3))\n",
    "cur[:,:,0] = XTest[0][:,:,0]\n",
    "cur[:,:,1:] = output[0]\n",
    "cur = lab2rgb(cur)\n",
    "imsave(\"recolor_11_25_18_18_23.png\", cur)\n",
    "imsave(\"gray_version_11_25_18_18_23.png\", rgb2gray(cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-eafb26d62e0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlab2rgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgist_earth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cur = lab2rgb(cur)\n",
    "im = Image.fromarray(np.uint8(cm.gist_earth(cur)*255))\n",
    "im"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
